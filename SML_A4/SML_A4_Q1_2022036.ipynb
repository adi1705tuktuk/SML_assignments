{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0gIVoOXyncC",
        "outputId": "3d7b6b41-bdbb-4100-f1f4-0c4c1928f77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from typing import Tuple\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "6-Ds7Vx9oqmh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature_index: int = None, threshold: float = None, value: int = None, left: 'Node' = None, right: 'Node' = None):\n",
        "        self.feature_index=feature_index\n",
        "        self.threshold=threshold\n",
        "        self.value=value\n",
        "        self.left=left\n",
        "        self.right=right\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X : np.ndarray, Y : np.ndarray, W : np.ndarray):\n",
        "        self.n_classes=len(set(Y))\n",
        "        self.n_features=X.shape[1]\n",
        "        self.node, alpha, best_wrong_indices=self.grow_trees(X, Y, W)\n",
        "        return alpha, best_wrong_indices\n",
        "\n",
        "    def grow_trees(self, X : np.ndarray, Y : np.ndarray, W : np.ndarray, depth : int=0):\n",
        "        if(depth==1):\n",
        "            return Node(value=np.argmax(np.bincount(Y))), None, None\n",
        "\n",
        "        best_loss, best_wrong_indices, best_feature, best_threshold=self._find_best_stump(X, Y, W)\n",
        "        if(best_loss==0):\n",
        "            best_loss=1e-6\n",
        "        alpha=np.log((1-best_loss)/best_loss)\n",
        "        left_indices, right_indices=self._split(X[: , best_feature], best_threshold)\n",
        "        left_node, _, _=self.grow_trees(X[left_indices], Y[left_indices], W, depth+1)\n",
        "        right_node, _, _=self.grow_trees(X[right_indices], Y[right_indices], W, depth+1)\n",
        "        return Node(feature_index=best_feature, threshold=best_threshold, left=left_node, right=right_node) ,alpha, best_wrong_indices\n",
        "\n",
        "    def predict(self, X : np.ndarray):\n",
        "         return np.array([self._traverse_tree(x, self.node) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, X : np.ndarray, node: Node):\n",
        "        if(node.left is None and node.right is None):\n",
        "            return node.value\n",
        "        if X[node.feature_index] <= node.threshold:\n",
        "            return self._traverse_tree(X, node.left)\n",
        "        else:\n",
        "            return self._traverse_tree(X, node.right)\n",
        "\n",
        "\n",
        "\n",
        "    def _find_best_stump(self, X : np.ndarray, Y : np.ndarray, W: np.ndarray):\n",
        "        best_loss=1.1\n",
        "        best_feature, best_threshold, best_wrong_indices=None, None, None\n",
        "\n",
        "        for feature_index in range(self.n_features):\n",
        "            sorted_indices=np.argsort(X[:,feature_index])\n",
        "            sorted_x=X[sorted_indices]\n",
        "            # sorted_y=Y[sorted_indices]\n",
        "            thresholds=np.unique(sorted_x[:, feature_index])\n",
        "            for threshold_index in range(len(thresholds)-1):\n",
        "                threshold=(thresholds[threshold_index]+thresholds[threshold_index+1])/2\n",
        "                left_indice,right_indice=self._split(X[:, feature_index], threshold)\n",
        "                loss, wrong_indices=self._calc_loss(Y[left_indice], Y[right_indice], W)\n",
        "                if(loss<best_loss):\n",
        "                    best_loss=loss\n",
        "                    best_wrong_indices=wrong_indices\n",
        "                    best_feature=feature_index\n",
        "                    best_threshold=threshold\n",
        "\n",
        "        return best_loss, best_wrong_indices, best_feature, best_threshold\n",
        "\n",
        "\n",
        "\n",
        "    def _calc_loss(self, y_left: np.ndarray , y_right : np.ndarray , W : np.ndarray):\n",
        "        left_val=np.argmax(np.bincount(y_left))\n",
        "        right_val=1-left_val\n",
        "        loss=1\n",
        "        left_misclassified_indices=np.where(y_left!=left_val)\n",
        "        right_misclassified_indices=np.where(y_right!=right_val)\n",
        "        misclassified_indices=np.concatenate((left_misclassified_indices[0], right_misclassified_indices[0]))\n",
        "        sum_misclassified=np.sum(W[misclassified_indices])\n",
        "        sum_weights=np.sum(W)\n",
        "        loss=sum_misclassified/sum_weights\n",
        "        return loss, misclassified_indices\n",
        "\n",
        "\n",
        "    def _split(self, X : np.ndarray , threshold : float):\n",
        "        left_indice=np.where(X<=threshold)[0]\n",
        "        right_indice=np.where(X>threshold)[0]\n",
        "        return left_indice, right_indice\n",
        "\n",
        "\n",
        "class BoostTree:\n",
        "    def __init__(self):\n",
        "        self.trees=[]\n",
        "        self.alphas=[]\n",
        "        self.weights=None\n",
        "\n",
        "    def _add(self, X : np.ndarray, Y: np.ndarray):\n",
        "        if(len(self.trees)==0):\n",
        "            self.weights=np.full(X.shape[0], 1/X.shape[0])\n",
        "\n",
        "        tree=DecisionTree()\n",
        "        alpha, wrong_indices=tree.fit(X, Y, self.weights)\n",
        "        self.alphas.append(alpha)\n",
        "        self.trees.append(tree)\n",
        "        self.weights[wrong_indices]*=np.exp(alpha)\n",
        "\n",
        "    def predict(self, X : np.ndarray):\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return np.array([np.sign(self.alphas[i]*predictions[i]) for i in range(len(self.alphas))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a-wgkF3yrry7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION** **1**"
      ],
      "metadata": {
        "id": "zr22FovOmBUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(selected_classes=[0, 1], random_subset_size=None):\n",
        "    data = np.load('/content/drive/MyDrive/SML_A4/mnist.npz')\n",
        "    x_train, y_train = data['x_train'], data['y_train']\n",
        "    x_test, y_test = data['x_test'], data['y_test']\n",
        "\n",
        "    train_mask = np.isin(y_train, selected_classes)\n",
        "    x_train = x_train[train_mask].reshape(train_mask.sum(), -1)\n",
        "    y_train = y_train[train_mask]\n",
        "\n",
        "    test_mask = np.isin(y_test, selected_classes)\n",
        "    x_test = x_test[test_mask].reshape(test_mask.sum(), -1)\n",
        "    y_test = y_test[test_mask]\n",
        "\n",
        "    if random_subset_size is not None:\n",
        "        random_indices = np.random.choice(len(x_train), size=random_subset_size, replace=False)\n",
        "        x_train = x_train[random_indices]\n",
        "        y_train = y_train[random_indices]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=1000, stratify=y_train, random_state=42)\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "def apply_pca(x_train, x_val, x_test, pca_dim=5):\n",
        "    pca = PCA(n_components=pca_dim)\n",
        "    x_train = pca.fit_transform(x_train)\n",
        "    x_val = pca.transform(x_val)\n",
        "    x_test = pca.transform(x_test)\n",
        "    return x_train, x_val, x_test\n",
        "\n",
        "def train_and_evaluate(x_train, y_train, x_val, y_val, x_test, y_test, epochs=50):\n",
        "    tree = BoostTree()\n",
        "    for _ in tqdm(range(epochs), desc='Training'):\n",
        "        tree._add(x_train, y_train)\n",
        "\n",
        "    y_pred_val = tree.predict(x_val)\n",
        "    val_accuracy = 100 * np.mean(y_pred_val == y_val)\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    y_pred_test = tree.predict(x_test)\n",
        "    test_accuracy = 100 * np.mean(y_pred_test == y_test)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "def main():\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test = load_and_preprocess_data()\n",
        "    x_train, x_val, x_test = apply_pca(x_train, x_val, x_test)\n",
        "    train_and_evaluate(x_train, y_train, x_val, y_val, x_test, y_test)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbh-9vXUmHBV",
        "outputId": "3abcec77-77c6-49b7-b1e1-9f634a35caca"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 50/50 [16:14<00:00, 19.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 98.18%\n",
            "Test Accuracy: 98.47%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}